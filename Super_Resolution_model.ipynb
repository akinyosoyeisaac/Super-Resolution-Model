{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nneji123/Super-Resolution-Model/blob/main/Super_Resolution_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the Repository and install the requirements_colab.txt file"
      ],
      "metadata": {
        "id": "srAVDHn_NQkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl5vXhJ9Zw-H"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Nneji123/Super-Resolution-Model.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R /content/Super-Resolution-Model/requirements_colab.txt /content\n",
        "!pip install -r requirements_colab.txt"
      ],
      "metadata": {
        "id": "leA5ul9FMcvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy the contents of the cloned Repository to the working directory"
      ],
      "metadata": {
        "id": "5L8nTZHcNVu5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2ZWESEcPFeWZ"
      },
      "outputs": [],
      "source": [
        "!cp -R /content/Super-Resolution-Model/RRDB_ESRGAN_x4.pth /content\n",
        "!cp -R /content/Super-Resolution-Model/RRDBNet_arch.py /content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and install Ngrok which is used for exposing the localhost so we can view the API with Google Colab."
      ],
      "metadata": {
        "id": "_vGyymRnNpyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ky9_S_GYCGz"
      },
      "outputs": [],
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6acAahCxJ975"
      },
      "outputs": [],
      "source": [
        "!tar -xvzf /content/ngrok-v3-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndH0raGDKmVR"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken 29vr8YhWZ9CDHrUq2kr0CpUA0e8_6ik4hU5GjJZeAYagTH5i4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiate the Colab Code module and the run the next cell to create the fastapi app."
      ],
      "metadata": {
        "id": "Ua2gsNebN2M7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1t9xUPrEU1g"
      },
      "outputs": [],
      "source": [
        "from colabcode import ColabCode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S2mhftpFCl4"
      },
      "outputs": [],
      "source": [
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile, Response\n",
        "from fastapi.responses import StreamingResponse, FileResponse\n",
        "import numpy as np\n",
        "import io\n",
        "from PIL import Image\n",
        "import torch\n",
        "import RRDBNet_arch as arch \n",
        "import cv2\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "model_path = 'RRDB_ESRGAN_x4.pth'  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
        "#device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n",
        "device = torch.device('cpu')\n",
        "\n",
        "model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
        "model.load_state_dict(torch.load(model_path), strict=True)\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "\n",
        "@app.post(\"/\")\n",
        "async def root(file: UploadFile = File(...)):\n",
        "    contents = io.BytesIO(await file.read())\n",
        "    file_bytes = np.asarray(bytearray(contents.read()), dtype=np.uint8)\n",
        "    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "    \n",
        "\n",
        "    img = img * 1.0 / 255\n",
        "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
        "    img_LR = img.unsqueeze(0)\n",
        "    img_LR = img_LR.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
        "    output = (output * 255.0).round()\n",
        "\n",
        "    \n",
        "    #cv2.imwrite('results.png', output)\n",
        "    #return Response('results.png', media_type=\"image/png\")\n",
        "    res, im_png = cv2.imencode(\".png\", output)\n",
        "    return StreamingResponse(io.BytesIO(im_png.tobytes()), media_type=\"image/png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m600ntArE49j"
      },
      "outputs": [],
      "source": [
        "cc = ColabCode(port=12000, code=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The API can then be viewed using the Public Url Generated by Colab Code."
      ],
      "metadata": {
        "id": "oXGw9-q3OCl_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6tFOk2ZFeTr",
        "outputId": "66027701-8b16-4d5c-e59c-2a774613bb83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [486]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://3a17-34-80-240-209.ngrok.io\" -> \"http://localhost:12000\"\n",
            "INFO:     102.89.39.104:0 - \"GET / HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     102.89.39.104:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     102.89.39.104:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.39.104:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.39.104:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.124:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.124:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.124:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.47.253:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     197.149.127.196:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     197.149.127.196:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.47.253:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.124:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.124:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.124:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.16:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.16:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.10:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.10:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.10:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.10:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.39.104:0 - \"POST / HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.16:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.105:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.89.38.105:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "cc.run_app(app=app)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Super_Resolution_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}